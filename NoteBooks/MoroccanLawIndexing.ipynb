{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dME9zIvc26V9"
      },
      "source": [
        "# Load Data From MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnRaPAJ3CIbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd5daf3d-17fb-4038-a00d-05c3cd020ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.18)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain_community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo pypdf langchain_community tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43-WmcBa29Bc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKt-r8hY2w-e"
      },
      "source": [
        "#  Extracting Content through PDF files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnrGCaeJBqPL"
      },
      "source": [
        "## Load Data From MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F7BSJnT20Z0"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    # Settings\n",
        "    username = \"teamds\"\n",
        "    password = \"teamds\"\n",
        "    database_name = \"moroccanlawdb\"\n",
        "    collection_name = \"moroccanlawcollection\"\n",
        "    uri = f\"mongodb+srv://{username}:{password}@moroccanlawcluster.3fnez.mongodb.net/?retryWrites=true&w=majority&appName=MoroccanLawCluster\"\n",
        "\n",
        "    client = MongoClient(uri)\n",
        "    db = client[database_name]\n",
        "    collection = db[collection_name]\n",
        "    documents = list(collection.find({}, {'Title': 1,\"Type\": 1, 'PDF_Link':1, '_id': 0}))\n",
        "\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrASbtVrCfwH"
      },
      "outputs": [],
      "source": [
        "laws = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir3NKV09NOHG",
        "outputId": "f2490016-e418-4779-bffa-74c18e5833e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': 'ظهير شريف رقم 1.58.250 بسن قانون الجنسية المغربية',\n",
              " 'Type': 'ظهير',\n",
              " 'PDF_Link': 'https://adala.justice.gov.ma/api/uploads/2024/07/22/%D9%82%D8%A7%D9%86%D9%88%D9%86%20%D8%A7%D9%84%D8%AC%D9%86%D8%B3%D9%8A%D8%A9-1721647191954.pdf#toolbar=0&statusbar=0'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "laws[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HYFJLk9NLSv",
        "outputId": "7b33b552-236d-474a-b980-7798f0d9f798"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "673"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "len(laws)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avuvZfbRBupc"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxh5j9X8L5rX",
        "outputId": "2adb78ef-f3d2-413d-e49e-c244deee6c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Types: 19\n",
            "Distinct Types: ['ظهير بمثابة قانون', 'النظام الداخلي', 'قانون تنظيمي', 'مدونة', 'دراسة', 'رأي', 'منشور', 'اتفاقية ثنائية', 'اتفاقية عامة', 'قانون', 'رسالة ملكية', 'مرسوم', 'تقرير', 'ظهير', '\\u200fمرسوم', 'ظهير (نسخ)', 'مرسوم (نسخ)', 'قرار', 'قرار مشترك']\n"
          ]
        }
      ],
      "source": [
        "# Extract distinct Type values\n",
        "distinct_types = {item[\"Type\"] for item in laws}\n",
        "\n",
        "# Convert to a list (optional) if order or indexing is needed\n",
        "distinct_types_list = list(distinct_types)\n",
        "\n",
        "print(\"Total Types:\", len(distinct_types_list))\n",
        "print(\"Distinct Types:\", distinct_types_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoU1an0jF4q5"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBZVMU2CFz4t"
      },
      "outputs": [],
      "source": [
        "# Function to process a single PDF\n",
        "def process_pdf(law):\n",
        "    try:\n",
        "        # Load the PDF using PyPDFLoader\n",
        "        loader = PyPDFLoader(law['PDF_Link'])\n",
        "\n",
        "        # Extract and split the text content of the PDF into pages\n",
        "        pages = loader.load_and_split()\n",
        "\n",
        "        # Extract text content\n",
        "        return [page.page_content for page in pages]\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {law['PDF_Link']}: {e}\")\n",
        "        return []  # Return an empty list if an error occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRLh5ycAF2LM"
      },
      "outputs": [],
      "source": [
        "# Main processing logic with multiprocessing\n",
        "def process_all_pdfs(laws):\n",
        "    pdf_texts = []\n",
        "\n",
        "    # Use ProcessPoolExecutor for parallel processing\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        # Submit tasks to the executor\n",
        "        futures = {executor.submit(process_pdf, law): law for law in laws}\n",
        "\n",
        "        # Use tqdm to track progress\n",
        "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing PDFs\", unit=\"file\"):\n",
        "            # Collect results\n",
        "            pdf_texts.extend(future.result())\n",
        "\n",
        "    return pdf_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdFq-l_GF7wC",
        "outputId": "86a227e5-8a2c-43f6-e14e-2a0a59af2c04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing PDFs: 100%|██████████| 673/673 [38:43<00:00,  3.45s/file]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ]
        }
      ],
      "source": [
        "# Process all PDFs\n",
        "pdf_texts = process_all_pdfs(laws)\n",
        "\n",
        "# Print or use the extracted texts\n",
        "print(pdf_texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pdf_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1-QYV7gXBXl",
        "outputId": "f653c686-a71d-4e95-ea35-4f52a9a3a06a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17081"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_texts[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "XXMYgH77XJ1d",
        "outputId": "036dd653-335c-4ce3-b25d-276bf4f68f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'- 2 - \\n \\nظهير شريف رقم1.58.250 بسن قانون الجنسية المغربية1 \\nكما تمتعديله بـ:  \\n-  القانون رقم  08.23  بتتميم المادة11  الصادر بتنفيذه الظهير الشريف رقم1.23.19 \\nبتاريخ19  من رجب1444  (10  فبراير2023)، الجريدة الرسمية عدد  7173  بتاريخ6  \\nشعبان1444 (27 فبراير2023)، ص2244؛ \\n-  القانون رقم  58.11  المتعلق بمحكمة النقض، المغير بموجبه الظهير الشريف رقم \\n1.57.223  الصادر في2  ربيع الأول1377  (27  سبتمبر1957) بشأن المجلس الأعلى\\nالصـ ادر ب ـت ـن ـفـي ـذه ال ـظـ هـي ـر ال ـشريف رقم  1.11.170  بتاريخ27  من ذي القعدة 1432  \\n(25  أكتوبر2011)، ال ـج ـري ـدة ال ـرسـمية عدد  5989  مكرر بتاريخ 28  ذو القعدة 1432 \\n(26 أكتوبر2011)، ص5228؛ \\n-  القانون رقم  62.06  الصادر بتنفيذهالظهير  الشريف رقم  1.07.80 بتاريخ3  ربيع\\nالأول  1428  )23  مارس2007(؛  الجريدة الرسمية عدد  5513  بتاريخ13  ربيع الأول \\n1428 )2 أبريل2007، ص1116.  \\n \\n1 - الجريدة الرسمية عدد2395 بتاريخ4 ربيع الأول1378 )19 شتنبر1958(، ص 2190.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BMtZliiHsnF"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lScwl_2MHiAs"
      },
      "outputs": [],
      "source": [
        "# Define a text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,  # Maximum size of each chunk\n",
        "    chunk_overlap=80  # Overlap between chunks for better context\n",
        ")\n",
        "\n",
        "# List to store all chunks\n",
        "chunks = []\n",
        "\n",
        "# Iterate through the text of each page\n",
        "for page_content in pdf_texts:\n",
        "    # Split the page content into chunks\n",
        "    page_chunks = text_splitter.split_text(page_content)\n",
        "\n",
        "    # Add the chunks to the list\n",
        "    chunks.extend(page_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kPf2SjNJ4ra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e119a9-6d0e-494f-f9e4-8c146e01a810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 73113\n"
          ]
        }
      ],
      "source": [
        "# Check the number of chunks generated\n",
        "print(f\"Total chunks: {len(chunks)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssk7EEVAJ6zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e133906-9b4e-4dd3-c347-10d2c1ad8adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1: قانون الجنسية المغربية \n",
            "صيغة محينة بتاريخ 27 فبراير2023\n",
            "\n",
            "Chunk 2: - 2 - \n",
            " \n",
            "ظهير شريف رقم1.58.250 بسن قانون الجنسية المغربية1 \n",
            "كما تمتعديله بـ:  \n",
            "-  القانون رقم  08.23  بتتميم المادة11  الصادر بتنفيذه الظهير الشريف رقم1.23.19 \n",
            "بتاريخ19  من رجب1444  (10  فبراير2023)، الجريدة الرسمية عدد  7173  بتاريخ6  \n",
            "شعبان1444 (27 فبراير2023)، ص2244؛ \n",
            "-  القانون رقم  58.11  المتعلق بمحكمة النقض، المغير بموجبه الظهير الشريف رقم \n",
            "1.57.223  الصادر في2  ربيع الأول1377  (27  سبتمبر1957) بشأن المجلس الأعلى\n",
            "\n",
            "Chunk 3: 1.57.223  الصادر في2  ربيع الأول1377  (27  سبتمبر1957) بشأن المجلس الأعلى\n",
            "الصـ ادر ب ـت ـن ـفـي ـذه ال ـظـ هـي ـر ال ـشريف رقم  1.11.170  بتاريخ27  من ذي القعدة 1432  \n",
            "(25  أكتوبر2011)، ال ـج ـري ـدة ال ـرسـمية عدد  5989  مكرر بتاريخ 28  ذو القعدة 1432 \n",
            "(26 أكتوبر2011)، ص5228؛ \n",
            "-  القانون رقم  62.06  الصادر بتنفيذهالظهير  الشريف رقم  1.07.80 بتاريخ3  ربيع\n",
            "الأول  1428  )23  مارس2007(؛  الجريدة الرسمية عدد  5513  بتاريخ13  ربيع الأول \n",
            "1428 )2 أبريل2007، ص1116.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Example output of first few chunks\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"Chunk {i+1}: {chunk}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "ufVs4lQWX67P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean a single chunk of text\n",
        "def clean_text(chunk):\n",
        "    # Remove extra spaces\n",
        "    chunk = re.sub(r'\\s+', ' ', chunk).strip()\n",
        "\n",
        "    # Normalize Arabic text\n",
        "    chunk = re.sub(r'[إأآ]', 'ا', chunk)\n",
        "    chunk = re.sub(r'ة', 'ه', chunk)\n",
        "\n",
        "    # Remove special characters (optional, adjust as needed)\n",
        "    chunk = re.sub(r'[^\\w\\s.,:؛؟!()-]', '', chunk)\n",
        "\n",
        "    return chunk"
      ],
      "metadata": {
        "id": "vr2yE-DsYbn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply cleaning to all chunks\n",
        "cleaned_chunks = [clean_text(chunk) for chunk in chunks]"
      ],
      "metadata": {
        "id": "MxJya2ZOYkCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some examples\n",
        "print(\"Original : \", chunks[1])\n",
        "print(\"Cleaned : \", cleaned_chunks[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H73-magGYmQg",
        "outputId": "094e4216-4828-4999-f2df-2adf66d7293a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original :  - 2 - \n",
            " \n",
            "ظهير شريف رقم1.58.250 بسن قانون الجنسية المغربية1 \n",
            "كما تمتعديله بـ:  \n",
            "-  القانون رقم  08.23  بتتميم المادة11  الصادر بتنفيذه الظهير الشريف رقم1.23.19 \n",
            "بتاريخ19  من رجب1444  (10  فبراير2023)، الجريدة الرسمية عدد  7173  بتاريخ6  \n",
            "شعبان1444 (27 فبراير2023)، ص2244؛ \n",
            "-  القانون رقم  58.11  المتعلق بمحكمة النقض، المغير بموجبه الظهير الشريف رقم \n",
            "1.57.223  الصادر في2  ربيع الأول1377  (27  سبتمبر1957) بشأن المجلس الأعلى\n",
            "Cleaned :  - 2 - ظهير شريف رقم1.58.250 بسن قانون الجنسيه المغربيه1 كما تمتعديله بـ: - القانون رقم 08.23 بتتميم الماده11 الصادر بتنفيذه الظهير الشريف رقم1.23.19 بتاريخ19 من رجب1444 (10 فبراير2023) الجريده الرسميه عدد 7173 بتاريخ6 شعبان1444 (27 فبراير2023) ص2244؛ - القانون رقم 58.11 المتعلق بمحكمه النقض المغير بموجبه الظهير الشريف رقم 1.57.223 الصادر في2 ربيع الاول1377 (27 سبتمبر1957) بشان المجلس الاعلى\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "GqbG4HXYZEGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save cleaned data as JSON\n",
        "with open(\"cleaned_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(cleaned_chunks, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"Cleaned data saved as cleaned_chunks.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbLPNb5iY9G5",
        "outputId": "99ff9137-9134-408b-a2e2-bc0f644a695f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data saved as cleaned_chunks.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO8rZrvB25VV"
      },
      "source": [
        "# Vector Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using API"
      ],
      "metadata": {
        "id": "_J8RfrdZ3Qos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time"
      ],
      "metadata": {
        "id": "w7kNyqlmxNpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHGbZDLl3BtP"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(texts):\n",
        "\n",
        "    API_URL = \"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/LaBSE\"\n",
        "\n",
        "    headers = {\"Authorization\": \"Bearer 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\"}\n",
        "\n",
        "    def query(payload):\n",
        "        response = requests.post(API_URL, headers=headers, json=payload)\n",
        "        result = response.json()\n",
        "\n",
        "        # Check if model is still loading\n",
        "        if 'error' in result and 'loading' in result['error']:\n",
        "            print(f\"Model is loading. Estimated time: {result.get('estimated_time', 'unknown')} seconds.\")\n",
        "            return None\n",
        "        return result\n",
        "\n",
        "    count=0\n",
        "    # Retry logic\n",
        "    embeddings = None\n",
        "    while embeddings is None:\n",
        "        embeddings = query({\n",
        "            \"inputs\": texts\n",
        "        })\n",
        "        if embeddings is None:\n",
        "            count+=1\n",
        "            # Wait for 10 seconds before retrying\n",
        "            time.sleep(10)\n",
        "        if count == 10:\n",
        "            return None\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_embeddings(cleaned_chunks[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okz9o1Bd2UAq",
        "outputId": "16ffa6a0-5cba-49fc-c339-29c03549d0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'error': 'Internal Server Error'}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to divide list into batches\n",
        "def split_into_batches(data, batch_size):\n",
        "    for i in range(0, len(data), batch_size):\n",
        "        yield data[i:i + batch_size]"
      ],
      "metadata": {
        "id": "ajUA0QQQyAP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define batch size\n",
        "batch_size = 100\n",
        "\n",
        "# Store embeddings\n",
        "all_embeddings = []\n",
        "\n",
        "# Initialize tqdm progress bar\n",
        "total_batches = len(cleaned_chunks) // batch_size + (1 if len(cleaned_chunks) % batch_size != 0 else 0)\n",
        "\n",
        "with tqdm(total=total_batches, desc=\"Processing Batches\") as pbar:\n",
        "    # Process batches\n",
        "    for batch in split_into_batches(cleaned_chunks, batch_size):\n",
        "        # Get embeddings for the current batch\n",
        "        batch_embeddings = get_embeddings(batch)\n",
        "\n",
        "        # Merge with the main embeddings list\n",
        "        all_embeddings.extend(batch_embeddings)\n",
        "\n",
        "        # Update the progress bar\n",
        "        pbar.update(1)"
      ],
      "metadata": {
        "id": "3R6JsrmTy5EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total embeddings: {len(all_embeddings)}\")"
      ],
      "metadata": {
        "id": "WKsVe3Vsz7Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Model"
      ],
      "metadata": {
        "id": "_vfhF3bZ3S8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQQY0Mcl3ar0",
        "outputId": "f6c44e87-acb7-4c9c-9288-d4e11566ec43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformer('sentence-transformers/LaBSE')"
      ],
      "metadata": {
        "id": "S8nBlbrR3cJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embedding_model.encode(cleaned_chunks[:100]) # Embedings Sample"
      ],
      "metadata": {
        "id": "dWkXcQB93ftO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAU8zQkv3yr3",
        "outputId": "8ed8dd37-55c7-48a6-ca36-6a2815724a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qsi6y-U3fXr"
      },
      "source": [
        "# Save Vector embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDgRezL43hVG"
      },
      "outputs": [],
      "source": [
        "!pip install pinecone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pc = Pinecone(api_key='pcsk_5shSMb_91Md5cJAMd4EfFYnDFNbqSYtPAYUTXPxaHLRRqWA8HwmHcBmsfQ3hjjECYX8Uia')\n",
        "\n",
        "index_name = 'moroccanlaw-index'"
      ],
      "metadata": {
        "id": "GeQh0h6FzJBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(all_embeddings):\n",
        "    # Ensure the index does not already exist, then create it\n",
        "    if index_name not in [item['name'] for item in pc.list_indexes()]:\n",
        "        pc.create_index(\n",
        "            name=index_name,\n",
        "            dimension=embeddings.shape[1],  # Replace with your model's dimension size\n",
        "            metric=\"cosine\",  # or \"dotproduct\", \"euclidean\"\n",
        "            spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "9z799gG6zLd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def connect_to_index(index_name=index_name):\n",
        "\n",
        "    return pc.Index(index_name)"
      ],
      "metadata": {
        "id": "PTui8SMPzNFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_vectors(all_embeddings, all_texts):\n",
        "    # Connect to the existing index\n",
        "    index = connect_to_index(index_name)\n",
        "\n",
        "    # Retrieve the total number of vectors currently in the index\n",
        "    total_records = index.describe_index_stats()['total_vector_count']\n",
        "\n",
        "    # Convert document embeddings to list of dictionaries for upsert\n",
        "    vectors = [\n",
        "        {\n",
        "            \"id\": str(i + total_records),  # Start ID from total_records\n",
        "            \"values\": embedding.tolist(),  # Convert each embedding to a list\n",
        "            \"metadata\": {\"text\": doc}  # Attach the corresponding document as metadata\n",
        "        }\n",
        "        for i, (embedding, doc) in enumerate(zip(all_embeddings, all_texts))\n",
        "    ]\n",
        "\n",
        "    # Upsert the vectors into the Pinecone index\n",
        "    index.upsert(vectors=vectors)\n",
        "\n",
        "    return True"
      ],
      "metadata": {
        "id": "zd4M7HDFza0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insert_vectors(embeddings,cleaned_chunks[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJEp47SI0Zxl",
        "outputId": "7de3dc61-b8be-4ddd-c24f-53a0590b6fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dME9zIvc26V9",
        "uKt-r8hY2w-e",
        "CnrGCaeJBqPL",
        "avuvZfbRBupc",
        "RO8rZrvB25VV",
        "_J8RfrdZ3Qos",
        "1qsi6y-U3fXr"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}